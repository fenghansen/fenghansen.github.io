<!DOCTYPE html>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Physics-guided Noise Neural Proxy for Low-light Raw Image Denoising</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  </head>

  <style>
  .section-title {
    font-family: "monospace"
  }
  .authors {
    font-family: "monospace";
  }
  h1, h2, h3, h4, h5, h6, p {
    font-family: "monospace";
  }
  </style>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-4">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h1 style="font-family: Lato;">Physics-guided Noise Neural Proxy for Practical Low-light Raw Image Denoising</h1>
            <h4 style="color:#5a6268;">TPAMI (Under Review)</h4>
            <hr>
            <h5> <a href="https://fenghansen.github.io/" target="_blank">Hansen Feng</a><sup>1</sup>, 
              <a href="https://wang-lizhi.github.io/" target="_blank">Lizhi Wang</a><sup>1</sup>, 
                Yiqi Huang<sup>1</sup>, Yuzhi Wang<sup>2</sup>, Lin Zhu<sup>1</sup>, Hua Huang<sup>3</sup>
            </h5>
            <p style="font-size: large; font-weight: 300;">
              <sup>1</sup>Beijing Institute of Technology &nbsp;&nbsp;
              <sup>2</sup>Megvii Technology &nbsp;&nbsp;
              <sup>3</sup>Beijing Normal University &nbsp;&nbsp; 
            </p>
            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/megvii-research/PMN/tree/TPAMI" role="button"  target="_blank">
                  <i class="fa fa-github"></i> Code (Eval. Only)</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://pan.baidu.com/s/1PgtH0Kw_mt1A56pF0Qt2gA?pwd=vmcl" role="button">
                    <i class="fa fa-cloud-download"></i> Checkpoints</a> </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Evaluation Guidelines</h3>
            <hr style="margin-top:0px">
          <p class="text-justify"> 
            Including <b>full images</b> (experiments in the paper) and <b>checkpoints</b> of our denoising neural network.  
            The <b>checkpoints</b> with config file can be loaded by the <a href="https://github.com/megvii-research/PMN/tree/TPAMI">existing project</a>, which has same evaluation process with this work. 
            More details for evaluation has shown in the <a href="https://pan.baidu.com/s/1PgtH0Kw_mt1A56pF0Qt2gA?pwd=vmcl">link</a>.
          </p>
          <!-- <img class="img-fluid" src="./images/pipeline.png" alt="teaser" width="90%"> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
          <p class="text-justify">
            In recent years, the mainstream practice for training low-light raw image denoising methods has shifted towards employing synthetic data. Noise modeling, which focuses on characterizing the noise distribution of real-world sensors, profoundly influences the effectiveness and practicality of synthetic data. Currently, physics-based noise modeling struggles to characterize the entire real noise distribution, while learning-based noise modeling impractically depends on paired real data. In this paper, we propose a novel strategy: learning the noise model from dark frames instead of paired real data, to break down the data dependency. Based on the proposed strategy, we introduce an efficient physics-guided noise neural proxy (PNNP) to approximate the real-world sensor noise model. Specifically, we integrate physical priors into neural proxies and introduce three efficient techniques: physics-guided noise decoupling (PND), physics-guided proxy model (PPM), and differentiable distribution loss (DDL). PND decouples the dark frame into different components and handles different levels of noise in a flexible manner, which reduces the complexity of noise modeling. PPM incorporates physical priors to constrain the generated noise, which promotes the accuracy of noise modeling. DDL provides explicit and reliable supervision for noise distribution, which promotes the precision of noise modeling. The proposed PNNP exhibits powerful potential in characterizing the real noise distribution. Extensive experiments on public datasets demonstrate superior performance in practical low-light raw image denoising.
          </p>
          <!-- <img class="img-fluid" src="./images/pipeline.png" alt="teaser" width="90%"> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Performance</h3>
            <hr style="margin-top:0px">
            <p class="text-justify" style="font-family: Lato; font-size: x-large; font-weight: 500;">Comparison</p>
            <h5>Quantitative Results</h5>
            <img class="img-fluid" src="./images/results_tab.png" width="100%">
            <p class="text-justify">
              Quantitative results (PSNR/SSIM) of different methods on the ELD dataset, SID dataset, and our LRID dataset. The red color indicates the best results and the blue color indicates the second-best results.
            </p>
            <details><summary>Click to get details</summary>
            <br>
            <h5>ELD dataset and SID dataset</h5>
            <img class="img-fluid" src="./images/results_ELD.png" width="100%">
            <br><br>
            <img class="img-fluid" src="./images/results_SID.png" width="100%">
            <p class="text-justify">
              <br> 
              Our method achieves the most exact color and clearest textures in the majority of scenarios in public datasets. Benefiting from accurate noise neural proxies, the corresponding denoising results are exempt from obvious residual noise and effectively remove various complex noises including fixed-pattern noise. 
            </p>
            <br>
            <h5>LRID dataset</h5>
            <img class="img-fluid" src="./images/results_tab_LRID.png" width="100%">
            <br>  
            <img class="img-fluid" src="./images/results_LRID.png" width="100%">
            </details>
            <br>  
            <p class="text-justify" style="font-family: Lato; font-size: x-large; font-weight: 500;">Ablation Study</p>
            <h5>Quantitative Results</h5>
            <img class="img-fluid" src="./images/ablation_tab.png" >
            <p class="text-justify">
              Ablation study of different modules we proposed on noise modeling and low-light raw image denoising. The underline indicates the best results.
            </p>
            <details><summary>Click to get details</summary>
            <br>
            <h5>Visual Results</h5>
            <img class="img-fluid" src="./images/ablation_fig.png">
            <p class="text-justify">
              A representative visual comparison of ablation studies on the ELD dataset. The red color indicates the best results and the blue color indicates the second-best results. (Best viewed with zoom-in)
            </p>
            <img class="img-fluid" src="./images/ablation_chart.png">
            <p class="text-justify">
              A distribution comparison of ablation studies on pixel-wise noise at ISO-1600. Each subfigure consists of two parts: the left part shows a comparison of the probability density functions, while the right part shows the probability plot. The blue histogram represents the distribution of real pixel-wise noise, while the orange histogram represents the distribution of synthetic noise. The red line represents the quantiles of the real noise distribution, and the blue points represent the quantiles of the synthetic noise distribution.
            </p>
            </details>
        </div>
        
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Discussion</h3>
            <hr style="margin-top:0px">
            <p class="text-justify" style="font-family: Lato; font-size: x-large; font-weight: 500;">Integration of Paired Real Data and Noise Modeling</p>
            <h5>Quantitative Results</h5>
            <img class="img-fluid" src="./images/discussion_Paired+NM_tab.png">  
            <p class="text-justify"> Comparison of denoising performance among noise modeling methods trained with and without paired real data. </p>
            <details><summary>Click to get details</summary>
            <img class="img-fluid" src="./images/discussion_Paired+NM.png">
            <br>
            <br>
            <p class="text-justify" style="font-family: Lato; font-size: x-large; font-weight: 500;">Data for Noise Modeling</p>
            <p class="text-justify">
              One important premise often overlooked in noise modeling research is that real data is always essential in practical noise modeling. 
              Learning-based approaches depend on real data to train noise models, while physics-based methods utilize real data for calibrating noise parameters. Although noise modeling methods are generally applicable, the model parameters exhibit sensor-specific characteristics. Hence, a robust and practical noise modeling approach should address the inherent challenges associated with real data quality.
              <br>
              The quality of real data directly influences the quality of the resulting noise model. The overlook for data is particularly severe in learning-based noise modeling methods. 
              The existing strategy of learning-based noise modeling, which involves learning the clean-to-noise mapping from paired real data, has several problems from a data perspective. 
              This strategy heavily depends on large-scale high-quality paired real data, which is often challenging to obtain. 
              On one side, underdeveloped data acquisition protocol often results in signal misalignment within the paired real data. 
              On the other side, the coupling of excessive noise models within the paired real data makes it challenging for neural networks to accurately approximate the real-world sensor noise model. 
              In summary, data defects hinder the performance of the existing learning-based noise modeling strategy in practical low-light scenarios.
              <br>
              Compared to learning-based noise modeling, physics-based noise modeling relies on real data collected by cameras specifically for calibration purposes, such as flat-field frames for calibrating signal-dependent noise and dark frames for calibrating signal-independent noise. The calibration process is independent of paired real data, eliminating signal misalignment. From the perspective of data dependency, the data required for physics-based noise modeling is easier to obtain and of higher quality compared to learning-based noise modeling. 
              <br>
              Based on these insights, we propose the strategy of learning the noise model from dark frames instead of paired real data. The data-centric perspective~\cite{data-centric} serves as the foundational principle guiding our analysis and problem-solving approach.
            </p>
            </details>
        </div>
        
      </div>
    </div>
  </section>

  <!-- citing -->
  <!-- <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{huang2021vs-net,
  title={VS-Net: Voting with Segmentation for Visual Localization},
  author={Huang, Zhaoyang and Zhou, Han and Li, Yijin and Yang, Bangbang and Xu, Yan and Zhou, Xiaowei and Bao, Hujun and Zhang, Guofeng and Li, Hongsheng},
  booktitle={CVPR},
  year={2021}
}</code></pre>
          <hr>
      </div>
    </div>
  </div> -->
  <footer class="text-center" style="margin-bottom:10px">
    <br>
      <p style="text-align:center;font-size:small;">
        Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template. <br>
        本站访客数<span id="busuanzi_value_site_uv"></span>人次<br>
        本文总阅读量<span id="busuanzi_value_page_pv"></span>次
      </p>
  </footer>

</body>
</html>
