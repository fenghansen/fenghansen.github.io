<!DOCTYPE html>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Physics-guided Noise Neural Proxy for Low-light Raw Image Denoising</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  </head>

  <style>
  .section-title {
    font-family: "monospace"
  }
  .authors {
    font-family: "monospace";
  }
  h1, h2, h3, h4, h5, h6, p {
    font-family: "monospace";
  }
  </style>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-4">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h1 style="font-family: Lato;">Physics-guided Noise Neural Proxy for Low-light Raw Image Denoising</h1>
            <h4 style="color:#5a6268;">IJCV (Under Review)</h4>
            <hr>
            <h5> <a href="https://fenghansen.github.io/" target="_blank">Hansen Feng</a><sup>1</sup>, 
              <a href="https://wang-lizhi.github.io/" target="_blank">Lizhi Wang</a><sup>1</sup>, 
                Yiqi Huang<sup>1</sup>, Yuzhi Wang<sup>2</sup>, Hua Huang<sup>3</sup>
            </h5>
            <p style="font-size: large; font-weight: 300;">
              <sup>1</sup>Beijing Institute of Technology &nbsp;&nbsp;
              <sup>2</sup>Megvii Technology &nbsp;&nbsp;
              <sup>3</sup>Beijing Normal University &nbsp;&nbsp; 
            </p>
            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/megvii-research/PMN/tree/TPAMI" role="button"  target="_blank">
                  <i class="fa fa-github"></i> Code </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://pan.baidu.com/s/1fXlb-Q_ofHOtVOufe5cwDg?pwd=vmcl" role="button">
                    <i class="fa fa-cloud-download"></i> Checkpoints</a> </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Evaluation Guidelines</h3>
            <hr style="margin-top:0px">
          <p class="text-justify">
            Coming soon... (ETA: 2023-08-04)
          </p>
          <!-- <img class="img-fluid" src="./images/pipeline.png" alt="teaser" width="90%"> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
          <p class="text-justify">Low-light raw image denoising plays a crucial role in mobile photography, and learning-based methods have become the mainstream approach. Training the learning-based methods with synthetic data emerges as an efficient and practical alternative to paired real data. However, the quality of synthetic data is inherently limited by the low accuracy of the noise model, which decreases the performance of low-light raw image denoising. In this paper, we develop a novel framework for accurate noise modeling that learns a physics-guided noise neural proxy (PNNP) from dark frames. PNNP integrates three efficient techniques: physics-guided noise decoupling (PND), physics-guided proxy model (PPM), and differentiable distribution-oriented loss (DDL). The PND decouples the dark frame into different components and handles different levels of noise in a flexible manner, which reduces the complexity of the noise neural proxy. The PPM incorporates physical priors to effectively constrain the generated noise, which promotes the accuracy of  the noise neural proxy. The DDL provides explicit and reliable supervision for noise modeling, which promotes the precision of the noise neural proxy. Extensive experiments on public low-light raw image denoising datasets and real low-light imaging scenarios demonstrate the superior performance of our PNNP framework.
          </p>
          <!-- <img class="img-fluid" src="./images/pipeline.png" alt="teaser" width="90%"> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Performance</h3>
            <hr style="margin-top:0px">
            <p class="text-justify" style="font-family: Lato; font-size: x-large; font-weight: 500;">Comparison</p>
            <h5>Quantitative Results</h5>
            <img class="img-fluid" src="./images/results_tab.png" width="100%">
            <p class="text-justify">
              Quantitative results (PSNR/SSIM) of different methods on the ELD dataset, SID dataset, and our LRID dataset. The red color indicates the best results and the blue color indicates the second-best results.
            </p>
            <!-- <details><summary>Click to get details</summary> -->
            <br>
            <h5>Public Datasets (ELD & SID)</h5>
            <img class="img-fluid" src="./images/results_ELD.png" width="100%">
            <br><br>
            <img class="img-fluid" src="./images/results_SID.png" width="100%">
            <p class="text-justify">
              <br> 
              Our method achieves the most exact color and clearest textures in the majority of scenarios in public datasets. Benefiting from accurate noise neural proxies, the corresponding denoising results are exempt from obvious residual noise and effectively remove various complex noises including fixed-pattern noise. 
            </p>
            <br>
            <h5>Real Imaging Scenarios</h5>
            <img class="img-fluid" src="./images/results_ours.png" width="100%">
            <!-- </details> -->
            <br>
            <p class="text-justify" style="font-family: Lato; font-size: x-large; font-weight: 500;">Ablation Study</p>
            <h5>Quantitative Results</h5>
            <img class="img-fluid" src="./images/ablation_tab.png" >
            <p class="text-justify">
              Ablation study of different modules we proposed on noise modeling and low-light raw image denoising. The underline indicates the best results.
            </p>
            <!-- <details><summary>Click to get details</summary> -->
            <br>
            <h5>Visual Results</h5>
            <img class="img-fluid" src="./images/ablation_fig.png">
            <p class="text-justify">
              A representative visual comparison of ablation studies on the ELD dataset. The red color indicates the best results and the blue color indicates the second-best results. (Best viewed with zoom-in)
            </p>
            <img class="img-fluid" src="./images/ablation_chart.png">
            <p class="text-justify">
              A distribution comparison of ablation studies on pixel-wise noise at ISO-1600. Each subfigure consists of two parts: the left part shows a comparison of the probability density functions, while the right part shows the probability plot. The blue histogram represents the distribution of real pixel-wise noise, while the orange histogram represents the distribution of synthetic noise. The red line represents the quantiles of the real noise distribution, and the blue points represent the quantiles of the synthetic noise distribution.
            </p>
            <!-- </details> -->
        </div>
        
      </div>
    </div>
  </section>
  <br>

  

  <!-- citing -->
  <!-- <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{huang2021vs-net,
  title={VS-Net: Voting with Segmentation for Visual Localization},
  author={Huang, Zhaoyang and Zhou, Han and Li, Yijin and Yang, Bangbang and Xu, Yan and Zhou, Xiaowei and Bao, Hujun and Zhang, Guofeng and Li, Hongsheng},
  booktitle={CVPR},
  year={2021}
}</code></pre>
          <hr>
      </div>
    </div>
  </div> -->
  <footer class="text-center" style="margin-bottom:10px">
    <br>
      <p style="text-align:center;font-size:small;">
        Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template. <br>
        本站访客数<span id="busuanzi_value_site_uv"></span>人次<br>
        本文总阅读量<span id="busuanzi_value_page_pv"></span>次
      </p>
  </footer>

</body>
</html>
